{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engines to test:\n",
    "### 1. Tesseract\n",
    "### 2. PaddleOCR\n",
    "### 3. EasyOCR\n",
    "\n",
    "## Dataset:\n",
    "\n",
    "https://guillaumejaume.github.io/FUNSD/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import time\n",
    "from pdf2image import convert_from_path\n",
    "from skimage.filters import threshold_niblack, threshold_sauvola\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from multiprocessing import Pool, cpu_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            filename                                               text\n",
      "0       82092117.png  TO: DATE: 3 Fax: NOTE: 82092117 614 -466 -5087...\n",
      "1  82200067_0069.png  TO: FROM: x SUBJECT:   DIVISION: DIVISION: DIV...\n",
      "2  82250337_0338.png  TO: FROM: DATE: MANUFACTURER: BRAND: Oct. Dec....\n",
      "3       82251504.png  17 cc: : From: Area: Region: 5 X Chains: Indep...\n",
      "4  82252956_2958.png  AUG 4 SEP 15 JUN 23 MAY 12 REGION: DIVISION: 7...\n"
     ]
    }
   ],
   "source": [
    "def get_path(default_path, prompt):\n",
    "    path = input(prompt + f\" (default: {default_path}): \")\n",
    "    return path if path else default_path\n",
    "\n",
    "annotations_folder = get_path('annotations', \"Enter the path to the annotations folder\")\n",
    "images_folder = get_path('images', \"Enter the path to the images folder\")\n",
    "\n",
    "if not os.path.exists(annotations_folder):\n",
    "    raise FileNotFoundError(f\"The specified annotations folder does not exist: {annotations_folder}\")\n",
    "if not os.path.exists(images_folder):\n",
    "    raise FileNotFoundError(f\"The specified images folder does not exist: {images_folder}\")\n",
    "\n",
    "data = []\n",
    "\n",
    "for filename in os.listdir(annotations_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        with open(os.path.join(annotations_folder, filename), 'r') as file:\n",
    "            annotation_data = json.load(file)\n",
    "            image_filename = filename.split('.')[0] + '.png'\n",
    "            text = \"\"\n",
    "            for item in annotation_data['form']:\n",
    "                text += item['text'] + \" \"\n",
    "\n",
    "            data.append({'filename': image_filename, 'text': text.strip()})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_otsu_binarization(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, bin_image = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return bin_image\n",
    "\n",
    "def apply_niblack_binarization(image, window_size, k=-0.2):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    bin_image = threshold_niblack(gray, window_size=window_size, k=k)\n",
    "    return (gray > bin_image).astype(np.uint8) * 255\n",
    "\n",
    "def apply_sauvola_binarization(image, window_size):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    bin_image = threshold_sauvola(gray, window_size=window_size)\n",
    "    return (gray > bin_image).astype(np.uint8) * 255\n",
    "\n",
    "def straighten_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "    \n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)\n",
    "    if lines is not None:\n",
    "        angles = []\n",
    "        for rho, theta in lines[:, 0]:\n",
    "            angle = (theta * 180 / np.pi) - 90\n",
    "            angles.append(angle)\n",
    "        median_angle = np.median(angles)\n",
    "        (h, w) = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w // 2, h // 2), median_angle, 1.0)\n",
    "        straightened = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "        return straightened\n",
    "    return image  \n",
    "\n",
    "def scale_image(image):\n",
    "    return cv2.resize(image, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "def apply_sauvola_binarization(image, window_size):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    bin_image = threshold_sauvola(gray, window_size=window_size)\n",
    "    return (gray > bin_image).astype(np.uint8) * 255\n",
    "\n",
    "def clean_borders(image):\n",
    "    # Ensure the image is grayscale\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    # Apply threshold\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Draw filled contours to remove border\n",
    "    for contour in contours:\n",
    "        cv2.drawContours(binary, [contour], 0, 0, -1)\n",
    "    return cv2.bitwise_not(binary)\n",
    "\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in ./OCR/lib/python3.9/site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging>=21.3 in ./OCR/lib/python3.9/site-packages (from pytesseract) (24.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in ./OCR/lib/python3.9/site-packages (from pytesseract) (10.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pytesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ocr_tesseract(image):\n",
    "    text = pytesseract.image_to_string(image, config='--psm 6')\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with window size: 11\n",
      "Evaluating with window size: 21\n",
      "Evaluating with window size: 31\n",
      "Evaluating with window size: 41\n",
      "Evaluating with window size: 51\n",
      "Evaluating with window size: 61\n",
      "Evaluating with window size: 71\n",
      "Evaluating with window size: 81\n",
      "Best method: sauvola, Best window size: 31, Levenshtein distance: 608.5\n"
     ]
    }
   ],
   "source": [
    "window_sizes = [11, 21, 31, 41, 51, 61, 71, 81]\n",
    "results = []\n",
    "\n",
    "def perform_ocr_tesseract(image):\n",
    "    text = pytesseract.image_to_string(image, config='--psm 6')\n",
    "    return text.strip()\n",
    "\n",
    "def evaluate_ocr(df, preprocessing_func, window_size):\n",
    "    df['ocr_text'] = df['filename'].apply(lambda x: perform_ocr_tesseract(preprocessing_func(cv2.imread(os.path.join(images_folder, x)), window_size)))\n",
    "    df['levenshtein'] = df.apply(lambda row: levenshtein_distance(row['text'], row['ocr_text']), axis=1)\n",
    "    avg_distance = df['levenshtein'].mean()\n",
    "    return avg_distance\n",
    "\n",
    "# Evaluate each preprocessing method with various window sizes\n",
    "for size in window_sizes:\n",
    "    print(f\"Evaluating with window size: {size}\")\n",
    "    \n",
    "    niblack_distance = evaluate_ocr(df.copy(), apply_niblack_binarization, size)\n",
    "    results.append(('niblack', size, niblack_distance))\n",
    "    \n",
    "    sauvola_distance = evaluate_ocr(df.copy(), apply_sauvola_binarization, size)\n",
    "    results.append(('sauvola', size, sauvola_distance))\n",
    "\n",
    "# Identify the best method and window size\n",
    "best_result = min(results, key=lambda x: x[2])\n",
    "print(f\"Best method: {best_result[0]}, Best window size: {best_result[1]}, Levenshtein distance: {best_result[2]}\")\n",
    "\n",
    "# Optional: save results to a CSV file for further analysis\n",
    "results_df = pd.DataFrame(results, columns=['method', 'window_size', 'levenshtein_distance'])\n",
    "results_df.to_csv('ocr_preprocessing_tesseract_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ablation Study Results:\n",
      "full_pipeline: 1056.32\n",
      "without_straightening: 1056.32\n",
      "without_scaling: 1056.32\n",
      "without_binarization: 1056.32\n",
      "without_border_cleaning: 713.88\n",
      "without_noise_removal: 1056.32\n"
     ]
    }
   ],
   "source": [
    "def perform_ocr_with_pipeline(image, steps, window_size):\n",
    "    if 'straightening' in steps:\n",
    "        image = straighten_image(image)\n",
    "    if 'scaling' in steps:\n",
    "        image = scale_image(image)\n",
    "    if 'binarization' in steps:\n",
    "        image = apply_sauvola_binarization(image, window_size)\n",
    "    if 'border_cleaning' in steps:\n",
    "        image = clean_borders(image)\n",
    "    if 'noise_removal' in steps:\n",
    "        image = remove_noise(image)\n",
    "    return perform_ocr_tesseract(image)\n",
    "\n",
    "def evaluate_ablation(args):\n",
    "    filename, text, steps, window_size = args\n",
    "    image = cv2.imread(os.path.join(images_folder, filename))\n",
    "    ocr_text = perform_ocr_with_pipeline(image, steps, window_size)\n",
    "    return levenshtein_distance(text, ocr_text)\n",
    "\n",
    "full_pipeline_steps = ['straightening', 'scaling', 'binarization', 'border_cleaning', 'noise_removal']\n",
    "results_ablation = []\n",
    "\n",
    "window_size = 31  # Use the best window size from Phase 1\n",
    "args_list = [(row['filename'], row['text'], full_pipeline_steps, window_size) for _, row in df.iterrows()]\n",
    "\n",
    "with Pool(cpu_count()) as p:\n",
    "    distances_full_pipeline = p.map(evaluate_ablation, args_list)\n",
    "\n",
    "avg_distance_full_pipeline = np.mean(distances_full_pipeline)\n",
    "results_ablation.append(('full_pipeline', avg_distance_full_pipeline))\n",
    "\n",
    "for step in full_pipeline_steps:\n",
    "    steps_without_step = [s for s in full_pipeline_steps if s != step]\n",
    "    args_list = [(row['filename'], row['text'], steps_without_step, window_size) for _, row in df.iterrows()]\n",
    "    with Pool(cpu_count()) as p:\n",
    "        distances_ablation = p.map(evaluate_ablation, args_list)\n",
    "    avg_distance_ablation = np.mean(distances_ablation)\n",
    "    results_ablation.append((f'without_{step}', avg_distance_ablation))\n",
    "\n",
    "results_ablation_df = pd.DataFrame(results_ablation, columns=['ablation_scenario', 'levenshtein_distance'])\n",
    "\n",
    "print(\"Ablation Study Results:\")\n",
    "for scenario, distance in results_ablation:\n",
    "    print(f\"{scenario}: {distance}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
